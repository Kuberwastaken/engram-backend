name: Download Materials

on:
  workflow_dispatch: 
    inputs:
      force_continue:
        description: 'Force continue from previous run'
        required: false
        default: false
        type: boolean
      batch_size_gb:
        description: 'Batch size in GB before committing (default: 10)'
        required: false
        default: '10'
        type: string
      rescan_content:
        description: 'Force rescan of existing content (ignore progress file)'
        required: false
        default: false
        type: boolean
  schedule:
    - cron: '0 2 * * 0'

jobs:
  download:
    runs-on: ubuntu-latest
    timeout-minutes: 320  # 5 hours and 20 minutes total (includes 20 min buffer for commit/push)
    
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4
      with:
        token: ${{ secrets.GITHUB_TOKEN }}
        fetch-depth: 1

    - name: Setup Node.js
      uses: actions/setup-node@v4
      with:
        node-version: '18'
        cache: 'npm'

    - name: Install dependencies
      run: npm install

    - name: Free up disk space
      run: |
        echo "🧹 Freeing up disk space on runner..."
        
        # Remove unnecessary packages and cache
        sudo apt-get autoremove -y
        sudo apt-get autoclean
        sudo rm -rf /usr/share/dotnet
        sudo rm -rf /usr/local/lib/android
        sudo rm -rf /opt/ghc
        sudo rm -rf /opt/hostedtoolcache/CodeQL
        sudo rm -rf /usr/local/share/boost
        sudo rm -rf "$AGENT_TOOLSDIRECTORY"
        
        echo "📊 Disk space after cleanup:"
        df -h /

    - name: Check initial disk space
      run: |
        echo "📊 Initial disk space status:"
        df -h /
        echo "💾 Available space: $(df -h / | awk 'NR==2{print $4}')"
        
        # Check if we have at least 8GB free
        AVAILABLE_GB=$(df / | awk 'NR==2{print int($4/1024/1024)}')
        echo "Available space: ${AVAILABLE_GB}GB"
        
        if [ $AVAILABLE_GB -lt 12 ]; then
          echo "⚠️ Warning: Only ${AVAILABLE_GB}GB available. Defaulting to smaller batch size."
          echo "BATCH_SIZE_GB=5" >> $GITHUB_ENV
        else
          echo "BATCH_SIZE_GB=${{ github.event.inputs.batch_size_gb || '10' }}" >> $GITHUB_ENV
        fi

    - name: Create Content directory
      run: mkdir -p Content

    - name: Configure Git (early setup)
      run: |
        git config --local user.email "action@github.com"
        git config --local user.name "GitHub Action"

    - name: Scan existing content and generate missing files list
      id: content_scan
      run: |
        echo "🔍 Scanning existing content and cross-checking with metadata..."
        
        # Create the content scanner script with .cjs extension for CommonJS
        cat > content-scanner.cjs << 'EOF'
        const fs = require('fs').promises;
        const path = require('path');
        
        async function scanExistingContent() {
          const contentDir = './Content';
          const progressFile = './download-progress.json';
          const forceRescan = process.env.FORCE_RESCAN === 'true';
          
          console.log('🔍 Starting content scan...');
          console.log(`Force rescan: ${forceRescan}`);
          
          // Get existing progress if available and not forcing rescan
          let existingProgress = { processed: new Set(), failed: new Set(), totalFiles: 0 };
          if (!forceRescan) {
            try {
              const progressData = await fs.readFile(progressFile, 'utf8');
              const progress = JSON.parse(progressData);
              existingProgress.processed = new Set(progress.processed || []);
              existingProgress.failed = new Set(progress.failed || []);
              existingProgress.totalFiles = progress.totalFiles || 0;
              console.log(`📄 Loaded existing progress: ${existingProgress.processed.size} processed, ${existingProgress.failed.size} failed`);
            } catch (error) {
              console.log('📄 No existing progress file found or invalid, starting fresh scan');
            }
          }
          
          // Scan actual files in Content directory
          const existingFiles = new Set();
          try {
            const scanDirectory = async (dir) => {
              const entries = await fs.readdir(dir, { withFileTypes: true });
              for (const entry of entries) {
                const fullPath = path.join(dir, entry.name);
                if (entry.isDirectory()) {
                  await scanDirectory(fullPath);
                } else if (entry.isFile()) {
                  // Store relative path from Content directory
                  const relativePath = path.relative(contentDir, fullPath);
                  existingFiles.add(relativePath);
                }
              }
            };
            
            await scanDirectory(contentDir);
            console.log(`📁 Found ${existingFiles.size} existing files in Content directory`);
          } catch (error) {
            console.log('📁 Content directory is empty or doesn\'t exist');
          }
          
          // Find all JSON metadata files that define what should be downloaded
          const metadataFiles = [];
          const findJsonFiles = async (dir) => {
            try {
              const entries = await fs.readdir(dir, { withFileTypes: true });
              for (const entry of entries) {
                const fullPath = path.join(dir, entry.name);
                if (entry.isDirectory() && entry.name !== 'Content' && !entry.name.startsWith('.')) {
                  await findJsonFiles(fullPath);
                } else if (entry.isFile() && entry.name.endsWith('.json') && entry.name !== 'download-progress.json') {
                  metadataFiles.push(fullPath);
                }
              }
            } catch (error) {
              // Directory doesn't exist or can't be read
            }
          };
          
          await findJsonFiles('./');
          console.log(`📋 Found ${metadataFiles.length} metadata JSON files`);
          
          // Parse metadata files to get list of files that should exist
          const expectedFiles = new Map(); // filename -> metadata
          for (const metadataFile of metadataFiles) {
            try {
              const content = await fs.readFile(metadataFile, 'utf8');
              const metadata = JSON.parse(content);
              
              // Handle different JSON structures - adapt this based on your metadata format
              if (Array.isArray(metadata)) {
                // Array of file objects
                for (const item of metadata) {
                  if (item.filename || item.name || item.file) {
                    const filename = item.filename || item.name || item.file;
                    expectedFiles.set(filename, { ...item, source: metadataFile });
                  }
                }
              } else if (metadata.files && Array.isArray(metadata.files)) {
                // Object with files array
                for (const item of metadata.files) {
                  if (item.filename || item.name || item.file) {
                    const filename = item.filename || item.name || item.file;
                    expectedFiles.set(filename, { ...item, source: metadataFile });
                  }
                }
              } else if (typeof metadata === 'object') {
                // Object with file entries
                for (const [key, value] of Object.entries(metadata)) {
                  if (typeof value === 'object' && (value.url || value.download_url)) {
                    expectedFiles.set(key, { ...value, source: metadataFile });
                  }
                }
              }
            } catch (error) {
              console.log(`⚠️ Error parsing ${metadataFile}: ${error.message}`);
            }
          }
          
          console.log(`📊 Expected ${expectedFiles.size} files based on metadata`);
          
          // Find missing files
          const missingFiles = [];
          const corruptedFiles = [];
          
          for (const [filename, metadata] of expectedFiles.entries()) {
            const isProcessed = existingProgress.processed.has(filename);
            const hasFailed = existingProgress.failed.has(filename);
            const fileExists = existingFiles.has(filename);
            
            if (!fileExists && !hasFailed) {
              // File doesn't exist and hasn't permanently failed
              missingFiles.push({ filename, metadata });
            } else if (fileExists) {
              // Check if file might be corrupted (size check)
              try {
                const filePath = path.join(contentDir, filename);
                const stats = await fs.stat(filePath);
                
                // Check for Google Drive error files (around 1.96KB)
                if (stats.size > 1950 && stats.size < 1970) {
                  console.log(`⚠️ Potential error file detected: ${filename} (${stats.size} bytes)`);
                  corruptedFiles.push({ filename, metadata, size: stats.size });
                  missingFiles.push({ filename, metadata }); // Re-download
                }
                
                // Check for suspiciously small files (less than 1KB for non-text files)
                else if (stats.size < 1024 && !filename.match(/\.(txt|json|xml|css|js)$/i)) {
                  console.log(`⚠️ Suspiciously small file: ${filename} (${stats.size} bytes)`);
                  corruptedFiles.push({ filename, metadata, size: stats.size });
                  missingFiles.push({ filename, metadata }); // Re-download
                }
              } catch (error) {
                console.log(`⚠️ Error checking file ${filename}: ${error.message}`);
                missingFiles.push({ filename, metadata }); // Re-download if can't check
              }
            }
          }
          
          // Generate download queue
          const downloadQueue = {
            missing: missingFiles,
            corrupted: corruptedFiles,
            total: missingFiles.length,
            existing: existingFiles.size,
            expected: expectedFiles.size,
            timestamp: new Date().toISOString()
          };
          
          // Save download queue
          await fs.writeFile('./download-queue.json', JSON.stringify(downloadQueue, null, 2));
          
          console.log(`✅ Scan complete:`);
          console.log(`   - Existing files: ${existingFiles.size}`);
          console.log(`   - Expected files: ${expectedFiles.size}`);
          console.log(`   - Missing files: ${missingFiles.length}`);
          console.log(`   - Corrupted files: ${corruptedFiles.length}`);
          
          return downloadQueue;
        }
        
        scanExistingContent().catch(console.error);
        EOF
        
        # Run the content scanner
        echo "🚀 Running content scanner..."
        FORCE_RESCAN="${{ github.event.inputs.rescan_content || 'false' }}" node content-scanner.cjs
        
        # Check results
        if [ -f "download-queue.json" ]; then
          MISSING_COUNT=$(node -e "const q = require('./download-queue.json'); console.log(q.total || 0);")
          EXISTING_COUNT=$(node -e "const q = require('./download-queue.json'); console.log(q.existing || 0);")
          echo "missing_files=${MISSING_COUNT}" >> $GITHUB_OUTPUT
          echo "existing_files=${EXISTING_COUNT}" >> $GITHUB_OUTPUT
          echo "queue_generated=true" >> $GITHUB_OUTPUT
          
          echo "📊 Content scan results:"
          echo "   Missing files: ${MISSING_COUNT}"
          echo "   Existing files: ${EXISTING_COUNT}"
        else
          echo "missing_files=0" >> $GITHUB_OUTPUT
          echo "existing_files=0" >> $GITHUB_OUTPUT
          echo "queue_generated=false" >> $GITHUB_OUTPUT
          echo "❌ Failed to generate download queue"
        fi

    - name: Debug - Check scan results
      run: |
        echo "📋 Scan Results Summary:"
        echo "Missing files: ${{ steps.content_scan.outputs.missing_files }}"
        echo "Existing files: ${{ steps.content_scan.outputs.existing_files }}"
        echo "Queue generated: ${{ steps.content_scan.outputs.queue_generated }}"
        
        if [ -f "download-queue.json" ]; then
          echo "📄 Download queue contents:"
          cat download-queue.json | head -50  # Show first 50 lines
        fi

    - name: Run targeted content downloader
      id: download_step
      if: steps.content_scan.outputs.missing_files != '0'
      run: |
        echo "🚀 Starting targeted content download process..."
        echo "Node version: $(node --version)"
        echo "NPM version: $(npm --version)"
        echo "Start time: $(date -u)"
        echo "Files to download: ${{ steps.content_scan.outputs.missing_files }}"
        
        # Create the targeted downloader script with .cjs extension
        cat > targeted-downloader.cjs << 'EOF'
        const fs = require('fs').promises;
        const path = require('path');
        const https = require('https');
        const http = require('http');
        const { pipeline } = require('stream/promises');
        const { createWriteStream, createReadStream } = require('fs');
        
        class TargetedDownloader {
          constructor() {
            this.batchSizeGB = parseFloat(process.env.BATCH_SIZE_GB || '10');
            this.batchSizeBytes = this.batchSizeGB * 1024 * 1024 * 1024;
            this.currentBatchSize = 0;
            this.downloadedCount = 0;
            this.failedCount = 0;
            this.batchCount = 0;
            this.progress = {
              processed: new Set(),
              failed: new Set(),
              totalFiles: 0,
              downloadedSize: 0,
              lastUpdated: new Date().toISOString()
            };
          }
          
          async loadQueue() {
            try {
              const queueData = await fs.readFile('./download-queue.json', 'utf8');
              const queue = JSON.parse(queueData);
              console.log(`📋 Loaded download queue with ${queue.total} files`);
              return queue.missing || [];
            } catch (error) {
              console.error('❌ Failed to load download queue:', error.message);
              return [];
            }
          }
          
          async loadProgress() {
            try {
              const progressData = await fs.readFile('./download-progress.json', 'utf8');
              const savedProgress = JSON.parse(progressData);
              this.progress.processed = new Set(savedProgress.processed || []);
              this.progress.failed = new Set(savedProgress.failed || []);
              this.progress.totalFiles = savedProgress.totalFiles || 0;
              this.progress.downloadedSize = savedProgress.downloadedSize || 0;
              console.log(`📄 Loaded existing progress: ${this.progress.processed.size} processed, ${this.progress.failed.size} failed`);
            } catch (error) {
              console.log('📄 No existing progress file, starting fresh');
            }
          }
          
          async saveProgress() {
            this.progress.lastUpdated = new Date().toISOString();
            this.progress.processed = Array.from(this.progress.processed);
            this.progress.failed = Array.from(this.progress.failed);
            
            await fs.writeFile('./download-progress.json', JSON.stringify(this.progress, null, 2));
            
            // Convert back to Sets for continued operation
            this.progress.processed = new Set(this.progress.processed);
            this.progress.failed = new Set(this.progress.failed);
          }
          
          async downloadFile(fileInfo) {
            const { filename, metadata } = fileInfo;
            const url = metadata.url || metadata.download_url || metadata.link;
            
            if (!url) {
              console.log(`⚠️ No download URL found for ${filename}`);
              this.progress.failed.add(filename);
              this.failedCount++;
              return false;
            }
            
            const filePath = path.join('./Content', filename);
            const fileDir = path.dirname(filePath);
            
            try {
              // Ensure directory exists
              await fs.mkdir(fileDir, { recursive: true });
              
              console.log(`⬇️ Downloading: ${filename}`);
              
              // Download file
              const response = await this.fetchWithRetry(url);
              if (!response || !response.ok) {
                throw new Error(`HTTP ${response?.status || 'unknown'}: ${response?.statusText || 'Unknown error'}`);
              }
              
              // Stream to file
              const fileStream = createWriteStream(filePath);
              await pipeline(response.body, fileStream);
              
              // Check file size
              const stats = await fs.stat(filePath);
              console.log(`✅ Downloaded: ${filename} (${this.formatBytes(stats.size)})`);
              
              // Check for Google Drive error files
              if (stats.size > 1950 && stats.size < 1970) {
                console.log(`⚠️ Potential Google Drive error file: ${filename}`);
                await fs.unlink(filePath); // Delete the error file
                throw new Error('Google Drive quota/error response detected');
              }
              
              this.progress.processed.add(filename);
              this.currentBatchSize += stats.size;
              this.progress.downloadedSize += stats.size;
              this.downloadedCount++;
              
              return true;
              
            } catch (error) {
              console.log(`❌ Failed to download ${filename}: ${error.message}`);
              
              // Clean up partial file
              try {
                await fs.unlink(filePath);
              } catch (cleanupError) {
                // File might not exist, ignore
              }
              
              this.progress.failed.add(filename);
              this.failedCount++;
              return false;
            }
          }
          
          async fetchWithRetry(url, maxRetries = 3) {
            for (let attempt = 1; attempt <= maxRetries; attempt++) {
              try {
                const response = await fetch(url, {
                  headers: {
                    'User-Agent': 'Mozilla/5.0 (compatible; ContentDownloader/1.0)'
                  },
                  timeout: 30000 // 30 second timeout
                });
                
                if (response.ok) {
                  return response;
                }
                
                if (response.status === 429) {
                  const retryAfter = response.headers.get('retry-after') || '60';
                  const waitTime = parseInt(retryAfter) * 1000;
                  console.log(`⏳ Rate limited, waiting ${retryAfter}s before retry ${attempt}/${maxRetries}`);
                  await this.sleep(waitTime);
                  continue;
                }
                
                if (attempt === maxRetries) {
                  return response; // Return last response for error handling
                }
                
              } catch (error) {
                if (attempt === maxRetries) {
                  throw error;
                }
                console.log(`🔄 Retry ${attempt}/${maxRetries} for ${url}: ${error.message}`);
                await this.sleep(2000 * attempt); // Exponential backoff
              }
            }
          }
          
          async commitBatch() {
            if (this.currentBatchSize === 0) return;
            
            this.batchCount++;
            console.log(`💾 Committing batch ${this.batchCount} (${this.formatBytes(this.currentBatchSize)})`);
            
            await this.saveProgress();
            
            // Git operations
            const { execSync } = require('child_process');
            try {
              execSync('git add Content/ download-progress.json', { stdio: 'inherit' });
              
              const commitMsg = `📚 Batch ${this.batchCount}: Downloaded ${this.downloadedCount} files (${this.formatBytes(this.progress.downloadedSize)}) - ${new Date().toISOString()}`;
              execSync(`git commit -m "${commitMsg}"`, { stdio: 'inherit' });
              execSync('git push', { stdio: 'inherit' });
              
              console.log(`✅ Batch ${this.batchCount} committed and pushed`);
            } catch (error) {
              console.log(`⚠️ Git operations failed: ${error.message}`);
            }
            
            this.currentBatchSize = 0;
          }
          
          async run() {
            console.log('🚀 Starting targeted download process...');
            
            await this.loadProgress();
            const downloadQueue = await this.loadQueue();
            
            if (downloadQueue.length === 0) {
              console.log('✅ No files to download');
              return;
            }
            
            this.progress.totalFiles = downloadQueue.length;
            console.log(`📊 Processing ${downloadQueue.length} files...`);
            
            for (let i = 0; i < downloadQueue.length; i++) {
              const fileInfo = downloadQueue[i];
              const filename = fileInfo.filename;
              
              // Skip if already processed or failed
              if (this.progress.processed.has(filename)) {
                continue;
              }
              
              console.log(`\n[${i + 1}/${downloadQueue.length}] Processing: ${filename}`);
              
              await this.downloadFile(fileInfo);
              
              // Commit batch if size limit reached
              if (this.currentBatchSize >= this.batchSizeBytes) {
                await this.commitBatch();
              }
              
              // Small delay to avoid overwhelming servers
              await this.sleep(100);
            }
            
            // Final commit
            if (this.currentBatchSize > 0) {
              await this.commitBatch();
            }
            
            await this.saveProgress();
            
            console.log('\n✅ Download process completed');
            console.log(`📊 Final stats: ${this.downloadedCount} downloaded, ${this.failedCount} failed`);
          }
          
          formatBytes(bytes) {
            if (bytes === 0) return '0 B';
            const k = 1024;
            const sizes = ['B', 'KB', 'MB', 'GB'];
            const i = Math.floor(Math.log(bytes) / Math.log(k));
            return parseFloat((bytes / Math.pow(k, i)).toFixed(2)) + ' ' + sizes[i];
          }
          
          sleep(ms) {
            return new Promise(resolve => setTimeout(resolve, ms));
          }
        }
        
        // Run the downloader
        const downloader = new TargetedDownloader();
        downloader.run().catch(console.error);
        EOF
        
        # Execute the targeted downloader with timeout
        if timeout 300m node targeted-downloader.cjs; then
          echo "✅ Download process completed successfully within time limit."
          echo "download_success=true" >> $GITHUB_OUTPUT
          echo "download_completed=true" >> $GITHUB_OUTPUT
        else
          EXIT_CODE=$?
          if [ $EXIT_CODE -eq 124 ]; then
            echo "⏰ Download process timed out after 5 hours. Will attempt to commit progress and continue."
            echo "download_success=true" >> $GITHUB_OUTPUT
            echo "download_completed=false" >> $GITHUB_OUTPUT
          else
            echo "❌ Download process failed with exit code: $EXIT_CODE"
            echo "download_success=false" >> $GITHUB_OUTPUT
            echo "download_completed=false" >> $GITHUB_OUTPUT
          fi
        fi
        
        echo "End time: $(date -u)"
      env:
        NODE_ENV: production
        BATCH_SIZE_GB: ${{ env.BATCH_SIZE_GB }}

    - name: Skip download notification
      if: steps.content_scan.outputs.missing_files == '0'
      run: |
        echo "✅ No missing files detected - all content is up to date!"
        echo "download_success=true" >> $GITHUB_OUTPUT
        echo "download_completed=true" >> $GITHUB_OUTPUT

    - name: Debug - Check final state
      if: always()
      run: |
        echo "📊 Final state check:"
        if [ -d "Content" ]; then
          TOTAL_FILES=$(find Content -type f | wc -l || echo "0")
          PDF_JSON_FILES=$(find Content -type f \( -name "*.pdf" -o -name "*.json" \) | wc -l || echo "0")
          TOTAL_SIZE=$(du -sh Content 2>/dev/null | cut -f1 || echo "0B")
          
          echo "Content directory exists with $TOTAL_FILES files"
          echo "PDF/JSON files: $PDF_JSON_FILES"
          echo "Total size: $TOTAL_SIZE"
          echo "First 10 files found in Content:"
          find Content -type f | head -10 || echo "No files found"
        else
          echo "❌ Content directory does not exist"
        fi
        
        # Check for potential error files
        if [ -d "Content" ]; then
          RATE_LIMIT_FILES=$(find Content -type f -size +1950c -size -1970c 2>/dev/null | wc -l || echo "0")
          echo "Potential Google Drive error files (approx 1.96KB): $RATE_LIMIT_FILES"
          if [ "$RATE_LIMIT_FILES" -gt "0" ]; then
            echo "⚠️ Warning: Found $RATE_LIMIT_FILES potential error files"
            find Content -type f -size +1950c -size -1970c 2>/dev/null | head -5
          fi
        fi
        
        # Check progress files
        for file in "download-progress.json" "download-queue.json"; do
          if [ -f "$file" ]; then
            echo "📄 $file found:"
            cat "$file" | head -20
          else
            echo "📄 $file not found"
          fi
          echo "---"
        done

    - name: Final commit check
      id: final_check
      if: always()
      run: |
        echo "🔍 Checking for any uncommitted changes..."
        if [ -n "$(git status --porcelain Content/ download-progress.json download-queue.json 2>/dev/null)" ]; then
          echo "final_changes=true" >> $GITHUB_OUTPUT
          echo "📝 Uncommitted changes detected"
          git status --short Content/ download-progress.json download-queue.json
        else
          echo "final_changes=false" >> $GITHUB_OUTPUT
          echo "✅ All changes have been committed or no changes made"
        fi

    - name: Final cleanup commit
      if: steps.final_check.outputs.final_changes == 'true'
      run: |
        echo "🧹 Making final cleanup commit..."
        
        TOTAL_FILES=$(find Content -type f 2>/dev/null | wc -l || echo "0")
        TOTAL_SIZE=$(du -sh Content 2>/dev/null | cut -f1 || echo "0B")
        TIMESTAMP=$(date -u +'%Y-%m-%d %H:%M:%S UTC')
        
        git add Content/
        git add download-progress.json
        git add download-queue.json
        git add -A
        
        COMMIT_MSG="📚 💾 Final sync: Content scan & download - Files: $TOTAL_FILES ($TOTAL_SIZE) - $TIMESTAMP - Run #${{ github.run_number }}"
        
        git config --local user.email "action@github.com"
        git config --local user.name "GitHub Action (Final Sync)"
        
        git commit -m "$COMMIT_MSG" || echo "No changes to commit"
        git push || echo "Nothing to push"

    - name: Trigger continuation workflow if needed
      if: steps.download_step.outputs.download_completed == 'false' && steps.content_scan.outputs.missing_files != '0'
      run: |
        echo "⏭️ Download was not completed fully. Triggering continuation..."
        curl -X POST \
          -H "Accept: application/vnd.github.v3+json" \
          -H "Authorization: token ${{ secrets.GITHUB_TOKEN }}" \
          -H "Content-Type: application/json" \
          https://api.github.com/repos/${{ github.repository }}/actions/workflows/download-materials.yml/dispatches \
          -d '{"ref":"${{ github.ref_name }}","inputs":{"force_continue":"true","batch_size_gb":"${{ github.event.inputs.batch_size_gb || env.BATCH_SIZE_GB || '10' }}","rescan_content":"false"}}'
        echo "✅ Continuation workflow triggered"

    - name: Upload artifacts
      if: always()
      uses: actions/upload-artifact@v4
      with:
        name: downloaded-content-${{ github.run_number }}
        path: |
          Content/
          download-progress.json
          download-queue.json
        retention-days: 30
        if-no-files-found: ignore

    - name: Print enhanced summary
      if: always()
      run: |
        DOWNLOAD_SUCCESS="${{ steps.download_step.outputs.download_success || 'true' }}"
        DOWNLOAD_COMPLETED="${{ steps.download_step.outputs.download_completed || 'true' }}"
        MISSING_FILES="${{ steps.content_scan.outputs.missing_files || '0' }}"
        EXISTING_FILES="${{ steps.content_scan.outputs.existing_files || '0' }}"
        
        echo "## 🚀 Content Sync Summary" >> $GITHUB_STEP_SUMMARY
        echo "- **Action Run**: #${{ github.run_number }}" >> $GITHUB_STEP_SUMMARY
        echo "- **Timestamp**: $(date -u)" >> $GITHUB_STEP_SUMMARY
        echo "- **Existing Files**: $EXISTING_FILES" >> $GITHUB_STEP_SUMMARY
        echo "- **Missing Files**: $MISSING_FILES" >> $GITHUB_STEP_SUMMARY
        echo "- **Download Status**: $DOWNLOAD_SUCCESS" >> $GITHUB_STEP_SUMMARY
        echo "- **Completed**: $DOWNLOAD_COMPLETED" >> $GITHUB_STEP_SUMMARY
        
        if [ -f "download-progress.json" ]; then
          echo "---" >> $GITHUB_STEP_SUMMARY
          echo "### 📋 Download Progress:" >> $GITHUB_STEP_SUMMARY
          echo "\`\`\`json" >> $GITHUB_STEP_SUMMARY
          cat download-progress.json >> $GITHUB_STEP_SUMMARY
          echo "\`\`\`" >> $GITHUB_STEP_SUMMARY
        fi
        
        if [ -f "download-queue.json" ]; then
          echo "---" >> $GITHUB_STEP_SUMMARY
          echo "### 🎯 Content Analysis:" >> $GITHUB_STEP_SUMMARY
          echo "\`\`\`json" >> $GITHUB_
